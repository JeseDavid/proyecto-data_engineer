# -*- coding: utf-8 -*-
"""Entregable-2-API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MMkJ3Rq1L_fjWTc4_b6bouRb2UgkOwL1

# Entregable: Proceso ETL en API Random User Generator
"""

# Importar librerías
import requests
import json
import pandas as pd
import psycopg2

"""## Descarga de los datos"""

# La API devuelve un usuario por cada consulta, por lo que ejecutamos un ciclo para obtener los usuarios deseados
total_users = 20
counter = 0
data = []

while counter < total_users:
  # Hacemos el request a la API
  response = requests.get('https://randomuser.me/api/')
  # Convertimos la data
  data_json = json.loads(response.text)
  data.append(data_json['results'][0])
  counter += 1

# Convertimos la data a un DataFrame
df = pd.json_normalize(data, sep='_')
# df

# df.columns

# df.dtypes

# df.to_csv('data_entregable_1.csv', index=False)

"""## Entrega 2 - Flujo para almacenar datos en Redshift"""

url="data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com"
data_base="data-engineer-database"
user="jese_salazar_coderhouse"
pwd = '4eMu5U9tjv0J'

try:
    conn = psycopg2.connect(
        host=url,
        dbname=data_base,
        user=user,
        password=pwd,
        port='5439'
    )
    print("Connected to Redshift successfully!")
    
except Exception as e:
    print("Unable to connect to Redshift.")
    print(e)

# Función para cargar los datos
from psycopg2.extras import execute_values

def cargar_en_redshift(conn, table_name, dataframe):
    dtypes= dataframe.dtypes
    cols= list(dtypes.index )
    tipos= list(dtypes.values)
    type_map = {'int64': 'INT','float64': 'FLOAT','object': 'VARCHAR(50)'}
    sql_dtypes = [type_map[str(dtype)] for dtype in tipos]
    # Definir formato SQL VARIABLE TIPO_DATO
    column_defs = [f"{name} {data_type}" for name, data_type in zip(cols, sql_dtypes)]
    # Combine column definitions into the CREATE TABLE statement
    table_schema = f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            {', '.join(column_defs)}
        );
        """
    # Crear la tabla
    cur = conn.cursor()
    cur.execute(table_schema)
    # Generar los valores a insertar
    values = [tuple(x) for x in dataframe.to_numpy()]
    # Definir el INSERT
    insert_sql = f"INSERT INTO {table_name} ({', '.join(cols)}) VALUES %s"
    # Execute the transaction to insert the data
    cur.execute("BEGIN")
    execute_values(cur, insert_sql, values)
    cur.execute("COMMIT")
    print('Proceso terminado')

# Carga de datos en RedShift
cargar_en_redshift(conn=conn, table_name='entregable_1', dataframe=df)

conn.close()